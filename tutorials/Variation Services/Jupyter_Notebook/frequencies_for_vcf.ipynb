{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# How to use NCBI Variation Services to compare frequencies for two populations for variations from a VCF file\n",
        "\n",
        "## Overview\n",
        "\n",
        "This tutorial will show how to get frequencies in African and Asian populations given VCF lines. There are 4 steps.\n",
        "\n",
        "1. Set up table headers metadata\n",
        "2. Convert VCF data lines to GRCh38 in [SPDI format](https://www.ncbi.nlm.nih.gov/variation/notation/)\n",
        "3. Retrieve all frequencies from the `overlapping_frequency_records` endpoint\n",
        "4. Display\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preparation\n",
        "\n",
        "We will need several packages:\n",
        "* `cyvcf2` - parse the input VCF\n",
        "* `requests` - access the Variation APIs\n",
        "* `ratelimit` - respect the volume limits on Variation APIs\n",
        "* `tqdm` - progress bar because some operations are slow\n",
        "* `tabulate` - final display\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q \"urllib3<2\" cyvcf2 requests ratelimit tabulate tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ratelimit import limits, sleep_and_retry\n",
        "from tqdm import tqdm\n",
        "import requests\n",
        "from cyvcf2 import VCF\n",
        "\n",
        "# Python library imports\n",
        "import tempfile\n",
        "from collections import namedtuple\n",
        "from operator import attrgetter, itemgetter\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### flatten() utility function\n",
        "\n",
        "This should be part of the language"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def flatten(iterable):\n",
        "    '''Return a list that flattens one level of nesting in nested lists'''\n",
        "    return list(itertools.chain.from_iterable(iterable))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `get()` utility function\n",
        "\n",
        "We'll be accessing the API a lot. The `get()` function below deals with some of the boilerplate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "VAR_API_URL = \"https://api.ncbi.nlm.nih.gov/variation/v0/\"\n",
        "\n",
        "@sleep_and_retry\n",
        "@limits(calls=1, period=1)  # Limit request rate to 1 RPS\n",
        "def get(endpoint, **params):\n",
        "    \"\"\"\n",
        "    Return the result of a Variation Services endpoint GET queery as a Python data structure.\n",
        "    Obeys API rate limits. Raises an exception on request failure.\n",
        "    \"\"\"\n",
        "    # Use the production SPDI service\n",
        "    api_url = \"https://www.ncbi.nlm.nih.gov/variation/v0/\" \\\n",
        "        if endpoint.startswith('spdi') else VAR_API_URL\n",
        "    reply = requests.get(VAR_API_URL + endpoint, params=params)\n",
        "    reply.raise_for_status()\n",
        "    return reply.json()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `Spdi` tuple\n",
        "\n",
        "SPDIs as named tuples are easier to work with than as dictionaries. The field names were chosen so that the way NCBI services return SPDI in JSON is easily convertible. If you have a dictionary `spdi_dict` from a service, you can convert it using `Spdi(**spdi_dict)`. As an added safeguard, Python will complain if there are any extra or missing fields."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Spdi = namedtuple('Spdi', 'seq_id position deleted_sequence inserted_sequence')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Table headers / population ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Populations we are interested in\n",
        "\n",
        "NCBI uses Biosample and Bioproject IDs to precisely identify the populations and studies to which it refers. The constants below give those IDs easier to remember names. You can find them at the `metadata/frequency` endpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# dbGaP's Allele Frequency Aggregator (ALFA) project\n",
        "BIOPROJECT_ID = \"PRJNA507278\"\n",
        "\n",
        "AAA_BIOSAMPLE_ID = 'SAMN10492703' # All African Ancestry\n",
        "ASN_BIOSAMPLE_ID = 'SAMN10492704' # Asian"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Table to convert biosample ids to human readable population names\n",
        "\n",
        "`POPULATION_NAMES` will hold a dictionary that converts biosample ids to human-readable names derived from the `metadata/frequency` endpoint. This will be used  later to display table headers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "POPULATION_NAMES = {}\n",
        "\n",
        "def add_populations(root_pop):\n",
        "    for pop in root_pop:\n",
        "        if 'subs' in pop:\n",
        "            add_populations(pop['subs'])\n",
        "        POPULATION_NAMES[pop['biosample_id']] = pop['name']\n",
        "\n",
        "for bioproject in get(\"metadata/frequency\"):\n",
        "    add_populations(bioproject['populations'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Input\n",
        "\n",
        "Below are our 20 variants of interest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "INPUT_VCF = \"\"\"##fileformat=VCFv4.0\n",
        "##contig=<ID=1,assembly=GCA_000001405.5,length=249250621>\n",
        "#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\n",
        "1\t82154\t.\tA\tG\t.\t.\t.\n",
        "1\t91472\t.\tC\tA,G,T\t.\t.\t.\n",
        "1\t570178\t.\tG\tA\t.\t.\t.\n",
        "1\t724702\t.\tG\tA,C,T\t.\t.\t.\n",
        "1\t726481\t.\tT\tG\t.\t.\t.\n",
        "1\t752566\t.\tG\tA,T\t.\t.\t.\n",
        "1\t752721\t.\tA\tC,G\t.\t.\t.\n",
        "1\t753541\t.\tG\tA\t.\t.\t.\n",
        "1\t754182\t.\tA\tG\t.\t.\t.\n",
        "1\t755775\t.\tA\tC,G,T\t.\t.\t.\n",
        "1\t758770\t.\tC\tA\t.\t.\t.\n",
        "1\t760300\t.\tA\tG\t.\t.\t.\n",
        "1\t760912\t.\tC\tT\t.\t.\t.\n",
        "1\t762320\t.\tC\tT\t.\t.\t.\n",
        "1\t768448\t.\tG\tA\t.\t.\t.\n",
        "1\t776546\t.\tA\tG\t.\t.\t.\n",
        "1\t779322\t.\tA\tG\t.\t.\t.\n",
        "1\t785989\t.\tT\tC\t.\t.\t.\n",
        "1\t798959\t.\tG\tA\t.\t.\t.\n",
        "1\t800007\t.\tT\tC\t.\t.\t.\n",
        "\"\"\"\n",
        "\n",
        "INPUT_VCF_ASSEMBLY = 'GCF_000001405.25'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Parsing VCF file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# creating a file with above vcf sample content, because cyvcf2 requires a physical file\n",
        "tp = tempfile.NamedTemporaryFile()\n",
        "tp.write(bytes(INPUT_VCF, 'utf-8'))\n",
        "tp.flush()\n",
        "\n",
        "# now parse the vcf file\n",
        "VCF_LINES = list(VCF(tp.name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conversion to SPDI and remapping\n",
        "\n",
        "The `vcf/.../contextuals` endpoint converts the first four VCF fields to a \"contextual\" SPDI. This means that the input variant will be expanded as required to eliminate ambiguity. The resulting SPDI will then be passed to the `canonical_representative` endpoint to remap it to the latest RefSeq assembly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "VCF_LINES_IN_SPDI_FORMAT = []\n",
        "\n",
        "def remap(spdi):\n",
        "    remap_url = 'spdi/{}:{}:{}:{}/canonical_representative'.format(*spdi)\n",
        "    return Spdi(**get(remap_url)['data'])\n",
        "\n",
        "for record in tqdm(VCF_LINES):\n",
        "    alts = ','.join(map(str, record.ALT))\n",
        "    query_url = f'vcf/{record.CHROM}/{record.POS}/{record.REF}/{alts}/contextuals'\n",
        "    spdis_for_alts = [Spdi(**spdi_dict) for spdi_dict in \n",
        "                      get(query_url, assembly=INPUT_VCF_ASSEMBLY)['data']['spdis']]\n",
        "\n",
        "    # If the VCF is not on the GRCh38 assembly, remap each SPDI to GRCh38.\n",
        "    if INPUT_VCF_ASSEMBLY != 'GCF_000001405.38':\n",
        "        spdis_for_alts = [remap(spdi) for spdi in spdis_for_alts]\n",
        "\n",
        "    VCF_LINES_IN_SPDI_FORMAT.append(spdis_for_alts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Retrieving frequency data\n",
        "\n",
        "For every line of the input VCF file, we query frequency data for the range that spans all corresponding SPDIs. This reduces the number of `http` requests needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "FREQUENCIES_FOR_VCF_LINES = []\n",
        "\n",
        "for spdis_for_alts in tqdm(VCF_LINES_IN_SPDI_FORMAT):\n",
        "    seq_id = spdis_for_alts[0].seq_id\n",
        "    min_pos = min(map(attrgetter('position'), spdis_for_alts))\n",
        "    max_pos_plus_one = max(map(lambda s: s.position + len(s.deleted_sequence), spdis_for_alts))\n",
        "\n",
        "    frequency_records = get(\n",
        "        'interval/{}:{}:{}/overlapping_frequency_records'.format(\n",
        "            seq_id,\n",
        "            min_pos,\n",
        "            max_pos_plus_one - min_pos))['results']\n",
        "\n",
        "    FREQUENCIES_FOR_VCF_LINES.append((seq_id, frequency_records))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reporting\n",
        "\n",
        "There may be more frequencies returned than there were original records since the service returns all variants that overlap the region. So, we need to report only those frequencies that correspond to alleles in the original file.\n",
        "\n",
        "First, we will prepare the frequency records for later look-up. The keys in the `ALLELE_FREQUENCIES` dictionary are SPDI tuples of the alleles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ALLELE_FREQUENCIES = {}\n",
        "\n",
        "def compute_frequencies(allele_counts):\n",
        "    total = float(sum(allele_counts.values()))\n",
        "    if total:\n",
        "        return {allele : count / total for allele, count in allele_counts.items()}\n",
        "    else:\n",
        "        return {allele: 0.0 for allele in allele_counts.keys()}\n",
        "\n",
        "for seq_id, frequency_records in FREQUENCIES_FOR_VCF_LINES:\n",
        "    for interval, interval_data in frequency_records.items():\n",
        "        length, position = map(int, interval.split('@'))\n",
        "        # Get counts for the dbGaP Allele Frequency Aggregation, ALFA, project.\n",
        "        allele_counts = interval_data['counts'][BIOPROJECT_ID]['allele_counts']\n",
        "        \n",
        "        aaa_frequencies = compute_frequencies(allele_counts[AAA_BIOSAMPLE_ID])\n",
        "        asn_frequencies = compute_frequencies(allele_counts[ASN_BIOSAMPLE_ID])\n",
        "\n",
        "        for allele in asn_frequencies.keys():\n",
        "            ALLELE_FREQUENCIES[Spdi(seq_id, position, interval_data['ref'], allele)] = \\\n",
        "                (aaa_frequencies[allele],\n",
        "                 asn_frequencies[allele])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we use the `ALLELE_FREQUENCIES` dictionary to attach frequency information to the SPDIs generated from the input VCF lines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TABLE_LINES = []\n",
        "\n",
        "def ref_spdi(spdi):\n",
        "    \"\"\"Spdi representing the reference allele\"\"\"\n",
        "    return Spdi(*attrgetter('seq_id','position',\n",
        "                            'deleted_sequence','deleted_sequence')(spdi))\n",
        "\n",
        "for vcf_line_number, spdis_for_alts in enumerate(VCF_LINES_IN_SPDI_FORMAT,\n",
        "                                                 start=1):\n",
        "    unique_alleles = set(flatten((s, ref_spdi(s)) for s in spdis_for_alts))\n",
        "\n",
        "    for allele in unique_alleles:\n",
        "        TABLE_LINES.append((vcf_line_number,\n",
        "                            allele.seq_id, \n",
        "                            allele.position,\n",
        "                            len(allele.deleted_sequence),\n",
        "                            '\\tRef' if allele.deleted_sequence == allele.inserted_sequence else ' ',\n",
        "                            allele.inserted_sequence,) +\n",
        "                           ALLELE_FREQUENCIES.get(allele, ('N/A', 'N/A')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now all that remains is to display the table constructed above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tabulate import tabulate\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "display(HTML(tabulate(sorted(TABLE_LINES),\n",
        "                      tablefmt='html',\n",
        "                      headers=['VCF Line',\n",
        "                               'Chromosome',\n",
        "                               'Position',\n",
        "                               'Len',\n",
        "                               'Ref',\n",
        "                               'Allele',\n",
        "                               POPULATION_NAMES[AAA_BIOSAMPLE_ID],\n",
        "                               POPULATION_NAMES[ASN_BIOSAMPLE_ID]])))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "RSNP-5075.ipynb",
      "provenance": [],
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}